{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关联分析 - Apriori\n",
    "\n",
    "所谓关联分析（关联规则学习）指的是从大规模数据集中学习到物品之间隐含的关系，Apriori基于该原理实现；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dataPath = '../../../git_mlaction/machinelearninginaction/Ch11/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关联分析\n",
    "\n",
    "Apriori算法：\n",
    "* 优点：易编码实现；\n",
    "* 缺点：在大数据集上速度慢；\n",
    "* 适用数据类型：数值型或标称型数据；\n",
    "\n",
    "关联分析是从大量数据中提取物品的隐含关系，这种关系有两种类型：\n",
    "* 频繁项集：指经常出现在一起的物品的集合；\n",
    "* 关联规则：指两种物品之间存在很强的关系；\n",
    "\n",
    "两个指标：\n",
    "* 支持度：一个项集的支持度被定义为数据集中包含该项集的比例值，最大为1，最小为0，该值可用于类似预剪枝的作用，提前终止算法；\n",
    "* 可信度：可信度用于评估关联规则，例如对于{尿布}->{啤酒}这样一对关联规则，它的可信度等于(支持度{尿布,啤酒})/(支持度{尿布})，也就是在所有包含尿布的记录中，我们的规则占比是多少，同样从0到1；\n",
    "\n",
    "从上述指标可以看出，如果要获取到所有支持度大于0.5的项集，可以穷举所有组合，然后统计其出现次数，除以总数即可，但是当物品很多时，这个组合（排列组合问题）也是很多的，如何优化这部分算法的性能，就是Apriori主要做的工作；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori原理\n",
    "\n",
    "对于物品之间的各种组合关系，可以通过下图来清晰呈现，假设我们只有四种物品，分别是0,1,2,3，此时所有组合如下：\n",
    "\n",
    "![物品排列组合](image/apriori.png)\n",
    "\n",
    "可以看到，所有组合总数为2\\*\\*N - 1，当物品种类为4时，有15种组合，那么当物品种类为100时呢，很快就超出了普通计算机的承受能力；\n",
    "\n",
    "Apriori原理简单描述是这样的：当一个项集频繁（高支持度）时，它的所有子集也是高频繁的，反过来就是当一个项目非频繁时，它的所有超集也都是非频繁的，即如果我们随机证明了{2,3}是非频繁的，那么我们就无须证明也能确定{0,2,3},{1,2,3},{0,1,2,3}同样是非频繁的，这就避免了由于种类的增加，导致要遍历的此处指数级上升的问题；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Apriori算法发现频繁项集\n",
    "\n",
    "算法基本流程：\n",
    "1. 从单个项集开始，计算各个项集是否满足最小支持度；\n",
    "2. 遍历所有满足的项集，遍历其各个组合；\n",
    "3. 重复1,2直到没有项集能够计算为止；\n",
    "\n",
    "对于最小支持度的设置要求较高，太低了会导致算法运行速度过慢，太高了会导致得到很少的频繁项集，看实际需求而定；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成候选项集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestDataSet():\n",
    "    return [[1,3,4], [2,3,5], [1,2,3,5], [2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({1}),\n",
       " frozenset({2}),\n",
       " frozenset({3}),\n",
       " frozenset({4}),\n",
       " frozenset({5})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for item in dataSet:\n",
    "        for v in item:\n",
    "            if not [v] in C1:\n",
    "                C1.append([v])\n",
    "    C1.sort()\n",
    "    return map(frozenset, C1) # 创建不变集合，注意frozenset对列表元素的要求\n",
    "\n",
    "createC1(loadTestDataSet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})],\n",
       " {frozenset({4}): 0.25,\n",
       "  frozenset({5}): 0.75,\n",
       "  frozenset({2}): 0.75,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({1}): 0.5})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 该函数负责从数据集D中计算出Ck中满足最小支持度的集合L\n",
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}\n",
    "    for data in D: # 遍历所有数据，统计Ck中各个项集的出现次数\n",
    "        for c in Ck:\n",
    "            if c.issubset(data):\n",
    "                if ssCnt.has_key(c):\n",
    "                    ssCnt[c] += 1\n",
    "                else:\n",
    "                    ssCnt[c] = 1\n",
    "    numD = float(len(D)) # 数据总数\n",
    "    L = []\n",
    "    supportData = {}\n",
    "    for k in ssCnt.keys():\n",
    "        support = ssCnt[k]/numD\n",
    "        if support >= minSupport:\n",
    "            L.insert(0, k)\n",
    "        supportData[k] = support\n",
    "    return L, supportData\n",
    "\n",
    "scanD(loadTestDataSet(), createC1(loadTestDataSet()), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组织完整的Apriori算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset([1, 3]), frozenset([1, 2]), frozenset([1, 5]), frozenset([2, 3]), frozenset([3, 5]), frozenset([2, 5])]\n",
      "[frozenset([1, 2, 3]), frozenset([1, 3, 5]), frozenset([1, 2, 5]), frozenset([2, 3, 5])]\n"
     ]
    }
   ],
   "source": [
    "# 定义函数实现由L1到C2的过程，即排列组合各个项集到一个更多元素的层次\n",
    "def aprioriGen(Lk, k):\n",
    "    Ck = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            # 只合并前k-2个项相同的项集，避免出现长度超过k的项集，比如{0,1}和{0,2}合并，满足条件，结果为{0,1,2}\n",
    "            # 但是如果是{0,1}和{2,3}则不满足前k-1个项相同的条件，因此不会合并出{0,1,2,3}这种case\n",
    "            L1, L2 = list(Lk[i])[:k-2], list(Lk[j])[:k-2]\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1 == L2:\n",
    "                Ck.append(Lk[i] | Lk[j])\n",
    "    return Ck\n",
    "\n",
    "gen1_2 = aprioriGen(scanD(loadTestDataSet(), createC1(loadTestDataSet()), 0.5)[0], 2)\n",
    "print gen1_2\n",
    "print aprioriGen(gen1_2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori算法主流程\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    C1 = createC1(dataSet)\n",
    "    D = map(set, dataSet)\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while(len(L[k-2])>1): # 其实某一层的项集数为1或更小的时候就结束了，因为1个项集无法组合成更高维度的超集\n",
    "        Ck = aprioriGen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[frozenset({1}), frozenset({3}), frozenset({2}), frozenset({5})],\n",
       "  [frozenset({1, 3}), frozenset({2, 5}), frozenset({2, 3}), frozenset({3, 5})],\n",
       "  [frozenset({2, 3, 5})]],\n",
       " {frozenset({5}): 0.75,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({2, 3, 5}): 0.5,\n",
       "  frozenset({1, 2}): 0.25,\n",
       "  frozenset({1, 5}): 0.25,\n",
       "  frozenset({3, 5}): 0.5,\n",
       "  frozenset({4}): 0.25,\n",
       "  frozenset({2, 3}): 0.5,\n",
       "  frozenset({2, 5}): 0.75,\n",
       "  frozenset({1}): 0.5,\n",
       "  frozenset({1, 3}): 0.5,\n",
       "  frozenset({2}): 0.75})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(loadTestDataSet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[frozenset({3}), frozenset({2}), frozenset({5})], [frozenset({2, 5})]],\n",
       " {frozenset({5}): 0.75,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({3, 5}): 0.5,\n",
       "  frozenset({4}): 0.25,\n",
       "  frozenset({2, 3}): 0.5,\n",
       "  frozenset({2, 5}): 0.75,\n",
       "  frozenset({1}): 0.5,\n",
       "  frozenset({2}): 0.75})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(loadTestDataSet(), 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，在apriori算法中，我们将最小支持度从0.5提高到0.75，符合条件的组合个数从9个下降到4个；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从频繁项集中挖掘关联规则\n",
    "\n",
    "关联规则的发现是依赖于频繁项集的（从计算公式中也可以看出，可信度是依赖于支持度的），基本算法流程类似频繁项集的获取，看下图：\n",
    "\n",
    "![关联规则计算](image/rules.png)\n",
    "\n",
    "与频繁项集不同的只是在项集前出现一个xxx->用于表示该项集潜在的关联规则；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数计算可信度\n",
    "def calcConf(freqSet, H, supportData, br1, minConf=0.7):\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq]\n",
    "        if conf >= minConf:\n",
    "            print freqSet - conseq, '---->', conseq, ' conf:', conf\n",
    "            br1.append((freqSet - conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数生成后选规则集合\n",
    "def rulesFromConseq(freqSet, H, supportData, br1, minConf=0.7):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m+1)):\n",
    "        Hmp1 = aprioriGen(H, m+1)\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, br1, minConf)\n",
    "        if (len(Hmp1) > 1):\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, br1, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关联规则主函数\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)): # 注意此处从1开始\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i>1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset([1]) ----> frozenset([3])  conf: 1.0\n",
      "frozenset([5]) ----> frozenset([2])  conf: 1.0\n",
      "frozenset([2]) ----> frozenset([5])  conf: 1.0\n",
      "[(frozenset([1]), frozenset([3]), 1.0), (frozenset([5]), frozenset([2]), 1.0), (frozenset([2]), frozenset([5]), 1.0)]\n"
     ]
    }
   ],
   "source": [
    "L, supportData = apriori(loadTestDataSet(), minSupport=0.5)\n",
    "rules = generateRules(L, supportData)\n",
    "print rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset([3]) ----> frozenset([1])  conf: 0.666666666667\n",
      "frozenset([1]) ----> frozenset([3])  conf: 1.0\n",
      "frozenset([5]) ----> frozenset([2])  conf: 1.0\n",
      "frozenset([2]) ----> frozenset([5])  conf: 1.0\n",
      "frozenset([3]) ----> frozenset([2])  conf: 0.666666666667\n",
      "frozenset([2]) ----> frozenset([3])  conf: 0.666666666667\n",
      "frozenset([5]) ----> frozenset([3])  conf: 0.666666666667\n",
      "frozenset([3]) ----> frozenset([5])  conf: 0.666666666667\n",
      "frozenset([5]) ----> frozenset([2, 3])  conf: 0.666666666667\n",
      "frozenset([3]) ----> frozenset([2, 5])  conf: 0.666666666667\n",
      "frozenset([2]) ----> frozenset([3, 5])  conf: 0.666666666667\n",
      "[(frozenset([3]), frozenset([1]), 0.6666666666666666), (frozenset([1]), frozenset([3]), 1.0), (frozenset([5]), frozenset([2]), 1.0), (frozenset([2]), frozenset([5]), 1.0), (frozenset([3]), frozenset([2]), 0.6666666666666666), (frozenset([2]), frozenset([3]), 0.6666666666666666), (frozenset([5]), frozenset([3]), 0.6666666666666666), (frozenset([3]), frozenset([5]), 0.6666666666666666), (frozenset([5]), frozenset([2, 3]), 0.6666666666666666), (frozenset([3]), frozenset([2, 5]), 0.6666666666666666), (frozenset([2]), frozenset([3, 5]), 0.6666666666666666)]\n"
     ]
    }
   ],
   "source": [
    "rules = generateRules(L, supportData, 0.5)\n",
    "print rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，降低可信度后，生成的关联规则明显多于降低前，也符合算法思想；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：发现国会投票中的模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：发现毒蘑菇的相似特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '3',\n",
       " '9',\n",
       " '13',\n",
       " '23',\n",
       " '25',\n",
       " '34',\n",
       " '36',\n",
       " '38',\n",
       " '40',\n",
       " '52',\n",
       " '54',\n",
       " '59',\n",
       " '63',\n",
       " '67',\n",
       " '76',\n",
       " '85',\n",
       " '86',\n",
       " '90',\n",
       " '93',\n",
       " '98',\n",
       " '107',\n",
       " '113']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushDatSet = [line.split() for line in open(dataPath+'mushroom.dat').readlines()]\n",
    "mushDatSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset(['2', '59'])\n",
      "frozenset(['39', '2'])\n",
      "frozenset(['2', '67'])\n",
      "frozenset(['2', '34'])\n",
      "frozenset(['2', '23'])\n",
      "frozenset(['2', '86'])\n",
      "frozenset(['76', '2'])\n",
      "frozenset(['90', '2'])\n",
      "frozenset(['2', '53'])\n",
      "frozenset(['93', '2'])\n",
      "frozenset(['63', '2'])\n",
      "frozenset(['2', '28'])\n",
      "frozenset(['2', '85'])\n",
      "frozenset(['2', '36'])\n"
     ]
    }
   ],
   "source": [
    "# 在毒蘑菇数据上运行apriori算法\n",
    "L, suppData = apriori(mushDatSet, minSupport=0.3)\n",
    "# 在结果中搜索包含有有毒特征值的项集组合\n",
    "for item in L[1]: # 暂时只从只有一个元素的项集中查找，否则结果太多\n",
    "    if item.intersection('2'):\n",
    "        print item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "关联分析是发现大数据集中隐含关系的一种方式，包括频繁项集和关联规则，二者对应指标为支持度和可信度，由于关联分析需要穷举所有可能的物品种类组合，因此非常耗时，此时就需要一种更加智能的算法来优化，Apriori算法就是用于此目的，它的思想很简单：如果一个项集是频繁的，那么它的所有子集都是频繁的，反之，如果一个项集是不频繁的，那么它所有的超集都是不频繁的，借助这一算法，我们可以将组合数大大降低；"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
